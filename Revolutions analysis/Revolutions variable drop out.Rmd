---
title: "Revolutions variable importance estimator"
author: "Sam McKay"
date: "18/05/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Written by Matthias Mauch and modified by Ben Lambert, Armand Leroi, Marina Papadopolou
See blog post by Ted Underwood critiquing the orginal Mauch et al. 2015 method; this revised method incorporates Underwood's recommended permutation on the diagonal https://tedunderwood.com/2016/02/07/you-say-you-found-a-revolution/

This estimates the impact of each variable on a given revolution by removing each variable sequentially

```{r}
rm(list=ls())
#libraries 
library(ggplot2)
library(plyr)
library(scales)
library(sads)
library(reshape2)
library(tidyr)
library(broom)
library(dplyr)
library(flexmix)
library(data.table)
```
import data
```{r}
data<- fread("EEpaperslong.csv", header=TRUE)
data<-subset(data, evolution_paper==1)
data$haldtopic<-as.character(data$haldtopic)
data<-subset(data, year > 1900 & year < 2010)
#data<-subset(data, year > 1920 & year < 1935)
#data<-subset(data, haldtopic=="topic1" | haldtopic=="topic2")
```
This is the step that needs to be automated. Here I am going to remove one variable manually. There are 20 of them.  They need to removed sequentially: no variables removed; variable 1 removed, variable 2 removed, variable 3 removed etc. 

Set palettes
```{r}
    greys<-floor(seq(from=90, to=1, length.out=30))
    greys<-paste("grey", greys, sep="")
    pal1<-c(greys)
    pal2<-c("indianred3", "steelblue3", "white")
```

```{r}
variables_effect <- function(data, save.directory = 'Evolution variable drop out.pdf'){
  
  # Define Foote Novelty functions
  
#wrapping function

  novelty.analysis <- function(dm, width.vector = c(1,2,3), ft.save.drcty = "foote.results.csv",
                               th.save.drcty = 'foote.thresh.csv', n.boot = 1000)
  {
    
    # ******************* #
    # INITIALIZING  : 
    
    #initialize output dataframes
    thresholds <- data.frame(matrix(nrow = length(width.vector), ncol = 3))
    thresh.header <- c('hw', 'lower_2.5', 'upper_97.5')
    colnames(thresholds) <- thresh.header
    
    foote.results <- data.frame(matrix(nrow = (length(dm[1,])*length(width.vector)), ncol = 3))
    foote.header <- c('year', 'foote.novelty', 'hw')
    colnames(foote.results) <- foote.header
    
    #count years
    years <-  length(rownames(dm))
    yearnames <- rownames(dm)
    
    # ******************* #
    # DEFINING FUNCTIONS : 
    
# 1. make the kernal
    make.foote.kernel <- function(half.width, taper.width.factor=0.4, middle.bit=1) {
      # Make the Foote kernel
      # parameters:
      #  taper.width.factor
      #    -- width of the Gaussian tapering (default 0.4; 0 = no tapering)
      #  middle.bit
      #    -- size of the center (default: 1, as in DoP paper, Foote uses 0)
      ones <- mat.or.vec(half.width, half.width) + 1
      short.strip <- mat.or.vec(half.width,middle.bit)
      top <- cbind(-ones,short.strip,ones)
      long.strip <- mat.or.vec(middle.bit,2*half.width+middle.bit)
      kernel <- rbind(top,long.strip,-top)
      if (taper.width.factor != 0) {
        gaussian <- dnorm(1:(2*half.width+middle.bit),
                          half.width+0.5+0.5*middle.bit,
                          2*taper.width.factor*half.width)
        kernel <- sweep(kernel,2,gaussian,'*')
        kernel <- sweep(kernel,1,gaussian,'*')
      }
      return(kernel)
    }
    
    #so this makes the kernal, which then gets put into the calculate.foote.novelty function, below, along with dm
    
# 2. calculate FN
    
    calculate.foote.novelty <- function(dm, kernel) {
      # Calculate the Foote novelty given a distance matrix dm and the Foote kernel
      n.date <- nrow(dm)
      kernel.width <- ncol(kernel)
      novelty <- mat.or.vec(n.date,1) * NA
      n.step <- n.date - kernel.width
      for (i in 1:n.step) {
        ind <- i-1+(1:kernel.width)
        novelty[i+ceiling(kernel.width/2)] <- sum(dm[ind,ind] * kernel)
      }
      return(novelty)
    }
    
     
# 3.  bootstrap
    
    diag.mm <- function(mat, offset=0, in.diag=c()) {
      n <- dim(mat)[1]
      m <- n-abs(offset)
      if (length(in.diag) == 0) {
        out.diag <- mat.or.vec(m,1)
        for (i in 1:m) {
          out.diag[i] <- mat[i, i+offset]
        }
        return(out.diag)
      }
      else {
        for (i in 1:m) {
          mat[i, i+offset] <- in.diag[i]
        }
        return(mat)
      }
    }
    
    shuffle.diagonals <- function(mat, symm=TRUE) {
      n <- dim(mat)[1]
      for (i in 0:(n-1)) {
        the.diag <- diag.mm(mat, offset=i)
        shuffled.diag <- sample(the.diag)
        mat <- diag.mm(mat, offset=i, in.diag=shuffled.diag)
      }
      mat[lower.tri(mat)] <- 0
      mat <- mat + t(mat) - diag(diag(mat))
      return(mat)
    }
    
    shuffled.bootstrap <- function(dm, kernel, n.boot) {
      # scrambled bootstrap
      n.boot <- 100
      foote.novelty <- calculate.foote.novelty(dm, kernel)
      n.nov <- length(foote.novelty)
      foote.novelty.scrambled <- mat.or.vec(n.boot, n.nov)
      for (i.boot in 1:n.boot) {
        shuffled.dm <- shuffle.diagonals(dm)
        foote.novelty.scrambled[i.boot,] <- calculate.foote.novelty(shuffled.dm, kernel)
      }
      thresh <- quantile(foote.novelty.scrambled, c(0.025,0.975), na.rm = T)
      return(thresh)
    }
    
# 4.  bind previous together, run, and return results in list
    run.foot.novelty <- function(distance.matrix, half.width,  n.boot = 1000){
      
      # results list to return:
      return.list <- list()
      
      # basic novelty
      kernel <- make.foote.kernel(half.width = half.width) # choose your half width; smaller half widths give higher resolution, but less power to detect discontinuities; larger half widths give less resolution, but more power. 
      
      foote.novelty <- calculate.foote.novelty(distance.matrix, kernel)
      
      # bootstrap
      thresh <- shuffled.bootstrap(distance.matrix, kernel, n.boot = n.boot ) # choose your number of bootstrap iterations
      
      #return thresholds
      return.list$Thresh <-thresh
      
      #=================
      # a simple plot of novelty including very simple 95% confidence thresholds
      
      print(plot(foote.novelty,type='b', main = paste('Novelty with half.width', half.width)))
      print(abline(h=thresh))
      
      # sort data for writing
      foote.res<-as.data.frame(foote.novelty)
      foote.res$year <- rownames(distance.matrix)
      
      # add results to return list
      return.list$Foote.res <- foote.res
      
      return(return.list)
    }

#RUNNING FOOTE NOVELTY FOR DIFFERENT WIDTHS     
    # run through width vector

    c <- 1
    y <- 1
    
    for (i in width.vector){
      foote.results[y:(y+years-1),3] <- i
      
      new.nov <- run.foot.novelty(dm, half.width = i , n.boot = n.boot)
      thresholds[c,] <- c(i, new.nov$Thresh)
      
      #foote.header<-c(foote.header, as.character(i))
      foote.results[y:(y+years-1),2] <- new.nov$Foote.res[,1]  
      foote.results[y:(y+years-1),1] <- yearnames
      
      c <- c+1
      y <- y + years
    }
    
    list.to.return <- list()
    list.to.return$Foote.res <- foote.results
    list.to.return$Thresh <- thresholds
    
    return(list.to.return)
    
    
  }

#START EXCLUDING VARIABLES LOOP

  res_full <- data.frame() # the big results dataframe
  pdf(save.directory) # open pdf to save plots
  
  for (i in c(0,levels(as.factor(data$haldtopic)))) {
    
    cat('\n**************************************\n')
    print(paste('Excluding topic ',i))
    
    d1<-subset(data, !haldtopic==i)
  
#get the data in the right shape for a distance matrix
d2 <- ddply(d1, .(haldtopic, year), summarise, mean=mean(prob))

d3<-dcast(d2,year~haldtopic, value.var="mean")
#b<-dcast(minus.var, year~haldtopic)
#b$year<-NULL
#b[order(b$year)]

#difference if needed

#b<-as.matrix(b)
#b<-scale(b)
#b<-diff(b,differences=1) 
d4<-data.frame(diff(as.matrix(d3), differences=1)) #NOTE:difference twice here

#use euclidean distance and scale
#transpose
d4$year<-NULL
rwsums<-rowSums(d4)
d4<-d4/rwsums
d5<-d4
d5$year<-NULL
d5<-as.matrix(d5)
d3.1<-d3[-c(1),] #If rho<0.25 then skip this step
year<-unique(d3.1$year) 
rownames(d5)<-year
d7<-t(d5)
d8<-KLdiv(as.matrix(d7))
d9<- d8
d9[lower.tri(d9)] <- 0
dm.ut<- d9
d9<- d8
d9[upper.tri(d9)] <- 0
dm.lt<- d9
dm.ut.s<- dm.ut + t(dm.ut)
dm.lt.s<- dm.lt + t(dm.lt)
dm.s<- dm.ut.s + dm.lt.s
dm.s<-sqrt(dm.s)
dm<-dm.s
dmh<-melt(dm)
#dmh<-as.matrix(dm)
names(dmh)<-c("year1", "year2", "distance")
    
    #name years in matrix, removing the first element to account for the differencing
   # yearmod<-tail(unique(data$year),-1) #removed -1
   # rownames(dm)<-yearmod
    #colnames(dm)<-yearmod
    #if not differencing use this:
    #year<-unique(data$year)
    #rownames(dm)<-year
    #colnames(dm)<-year
   
#heatmap
    par(mfrow= c(1,1))
 
    if (i == 0){
      #heatmap(dmh ,Rowv= NA, Colv = NA, main = 'Heatmap with all variables')
    hplot<-ggplot()+
geom_tile(data=dmh, aes(x=year1,y=year2,fill=distance))+
scale_fill_continuous(low="lightgoldenrod1", high="coral3")+
ylab("year")+
xlab("year")+
  ggtitle("Heatmap with all variables")+
guides(colour=FALSE, fill=FALSE)+
scale_x_continuous(breaks=pretty_breaks(n=5), limits=c(min(dmh$year1), max(dmh$year1)))+#
scale_y_continuous(breaks=pretty_breaks(n=5), limits=c(min(dmh$year2), max(dmh$year2)))+
theme_classic(base_size = 12, base_family = "sans")+
theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), legend.position="bottom", text=element_text(size=10,  family="sans", colour = 'black'))
    print(hplot)
    }
    else{
      title<-(paste("Heatmap without topic", i ))
      #heatmap(dmh ,Rowv= NA, Colv = NA, main = paste('Heatmap without variable', i))
      ggplot()+
geom_tile(data=dmh, aes(x=year1,y=year2,fill=distance))+
scale_fill_continuous(low="lightgoldenrod1", high="coral3")+
ylab("year")+
xlab("year")+
  ggtitle(title)+
guides(colour=FALSE, fill=FALSE)+
scale_x_continuous(breaks=pretty_breaks(n=5), limits=c(min(dmh$year1), max(dmh$year1)))+#
scale_y_continuous(breaks=pretty_breaks(n=5), limits=c(min(dmh$year2), max(dmh$year2)))+
theme_classic(base_size = 12, base_family = "sans")+
theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), legend.position="bottom", text=element_text(size=10,  family="sans", colour = 'black'))
      print(hplot)
      }

#Running foote novelty
    #calculate max_k, and use as upperlimit on k

    max_k<-floor((length(unique(rownames(dm)))-2)/2)
    
    #pdf(paste('novelty_excl_',i, '.pdf', sep = ''))
    par(mfrow = c(3,2))
    foote.results<-novelty.analysis(dm, c(1:max_k)) #here set the range of kernal half-widths you want to use. 

    #dev.off()

    #put foote.results into a nice data frame.  This is the data frame which has to be extended so that it has an extra column telling us what variable is excluded (say "1" or "0" for "no variables excluded; so that if there are n variables, the final data frame will be these results x n variables long)
#plot nicely

    t<-foote.results$Thresh
    td<-as.data.frame(t)
    f<-foote.results$Foote.res
    fd<-as.data.frame(f)
    res<-merge(fd, t, by.x="hw", by.y="hw")
    res$year<-as.numeric(as.character(res$year))
    res$foote.novelty<-as.numeric(as.character(res$foote.novelty))
    res$upper<-ifelse(res$foote.novelty>=res$upper_97.5, 1, 0)
    res$lower<-ifelse(res$foote.novelty<=res$lower_2.5, 1, 0)
    res$excl_var <- c(rep(i,length(res[,1])))
    res<-as.data.table(res)
res<-res %>% group_by(hw) %>% mutate(bin = cut(foote.novelty, breaks = 30,labels=1:30, include.lowest = TRUE))
res<-as.data.frame(res)
res$bin<-as.factor(res$bin)
    res$revcons<-as.character(ifelse(res$foote.novelty>=res$upper_97.5, "rev", ifelse(res$foote.novelty<=res$lower_2.5, "cons", "neither")))
    res$revcons[is.na(res$revcons)] <- "NA"
res$revcons<- factor(res$revcons, levels = c("rev", "cons", "NA"))
res<-as.data.frame(res)
    # add newest results to big dataframe
    res_full <- rbind(res_full,res) 
    
    #Plot FNplot
  if(i ==0){
    par(mfrow= c(1,1))
    title<-(paste("FNplot of all evolution papers"))
    fnplot2<-ggplot()+
    geom_tile(data=res_full, aes(x=year,y=hw,fill=as.factor(bin)))+
    scale_fill_manual(values=c(pal1), na.value=NA)+
    geom_point(data=res_full, aes(x=year,y=hw, colour=as.factor(revcons)), size=2, alpha=1)+
    scale_colour_manual(values=c(pal2))+
    ylab("k")+
    xlab("year")+
    ggtitle(title)+
    guides(colour=FALSE, fill=FALSE)+
    #geom_rect(aes(xmin=1895, xmax=1905, ymin=0, ymax=20), fill="red", alpha=0.2)+ #revolution 1
    #geom_rect(aes(xmin=1950, xmax=1994, ymin=0, ymax=59), fill="red", alpha=0.2)+ #revolution 1
    scale_x_continuous(breaks=pretty_breaks(n=5), limits=c(min(res_full$year), max(res_full$year)))+#
    scale_y_continuous(breaks=pretty_breaks(n=10), limits=c(0, max_k))+
    theme_classic(base_size = 12, base_family = "sans")+
    theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), legend.position="bottom", text=element_text(size=10,  family="sans", colour = 'black'))
    print(fnplot2)
  }
  else{
    par(mfrow= c(1,1))
    title<-(paste("FNplot of evolution papers excl. topic", i ))
  
    fnplot2<-ggplot()+
    geom_tile(data=res_full, aes(x=year,y=hw,fill=as.factor(bin)))+
    scale_fill_manual(values=c(pal1), na.value=NA)+
    geom_point(data=res_full, aes(x=year,y=hw, colour=as.factor(revcons)), size=2, alpha=1)+
    scale_colour_manual(values=c(pal2))+
    ylab("k")+
    xlab("year")+
    ggtitle(title)+
    guides(colour=FALSE, fill=FALSE)+
    #geom_rect(aes(xmin=1895, xmax=1905, ymin=0, ymax=20), fill="red", alpha=0.2)+ #revolution 1
    #geom_rect(aes(xmin=1950, xmax=1994, ymin=0, ymax=59), fill="red", alpha=0.2)+ #revolution 1
    scale_x_continuous(breaks=pretty_breaks(n=5), limits=c(min(res_full$year), max(res_full$year)))+#
    scale_y_continuous(breaks=pretty_breaks(n=10), limits=c(0, max_k))+
    theme_classic(base_size = 12, base_family = "sans")+
    theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), legend.position="bottom", text=element_text(size=10,  family="sans", colour = 'black'))
    print(fnplot2)
      }
  }
#Given these data, I will then figure out how to identify which variables are most important to a revolution.  Not exactly sure how --- there are various metrics I can use. 

  dev.off() #close pdf where we were saving everything
  write.csv(res_full, "evolution_topics_all.csv", row.names=FALSE)
  write.csv(dm, "data_matrix.csv", row.names=FALSE)
  return(res_full)
}
```

```{r}
res.full <- variables_effect(data)
res.full<-res.full%>%
  arrange(excl_var,year,hw)
res.full$revcons[is.na(res.full$revcons)] <- "NA"
res.full<-res.full[complete.cases(res.full), ]
res.full$revcons<- factor(res.full$revcons, levels = c("rev", "cons", "NA"))
write.csv(res.full, "evolution_revolution_dropout.csv", row.names=FALSE)
res.rev<-subset(res.full, revcons=="rev")
```

import data
```{r}
data<- fread("EEpaperslong.csv", header=TRUE)
data<-subset(data, ecology_paper==1)
data$haldtopic<-as.character(data$haldtopic)
data<-subset(data, year > 1900 & year < 2010)
#data<-subset(data, year > 1920 & year < 1935)
#data<-subset(data, haldtopic=="topic1" | haldtopic=="topic2")
```
This is the step that needs to be automated. Here I am going to remove one variable manually. There are 20 of them.  They need to removed sequentially: no variables removed; variable 1 removed, variable 2 removed, variable 3 removed etc. 

Set palettes
```{r}
    greys<-floor(seq(from=90, to=1, length.out=30))
    greys<-paste("grey", greys, sep="")
    pal1<-c(greys)
    pal2<-c("indianred3", "steelblue3", "white")
```

```{r}
variables_effect <- function(data, save.directory = 'Ecology variable drop out.pdf'){
  
  # Define Foote Novelty functions
  
#wrapping function

  novelty.analysis <- function(dm, width.vector = c(1,2,3), ft.save.drcty = "foote.results.csv",
                               th.save.drcty = 'foote.thresh.csv', n.boot = 1000)
  {
    
    # ******************* #
    # INITIALIZING  : 
    
    #initialize output dataframes
    thresholds <- data.frame(matrix(nrow = length(width.vector), ncol = 3))
    thresh.header <- c('hw', 'lower_2.5', 'upper_97.5')
    colnames(thresholds) <- thresh.header
    
    foote.results <- data.frame(matrix(nrow = (length(dm[1,])*length(width.vector)), ncol = 3))
    foote.header <- c('year', 'foote.novelty', 'hw')
    colnames(foote.results) <- foote.header
    
    #count years
    years <-  length(rownames(dm))
    yearnames <- rownames(dm)
    
    # ******************* #
    # DEFINING FUNCTIONS : 
    
# 1. make the kernal
    make.foote.kernel <- function(half.width, taper.width.factor=0.4, middle.bit=1) {
      # Make the Foote kernel
      # parameters:
      #  taper.width.factor
      #    -- width of the Gaussian tapering (default 0.4; 0 = no tapering)
      #  middle.bit
      #    -- size of the center (default: 1, as in DoP paper, Foote uses 0)
      ones <- mat.or.vec(half.width, half.width) + 1
      short.strip <- mat.or.vec(half.width,middle.bit)
      top <- cbind(-ones,short.strip,ones)
      long.strip <- mat.or.vec(middle.bit,2*half.width+middle.bit)
      kernel <- rbind(top,long.strip,-top)
      if (taper.width.factor != 0) {
        gaussian <- dnorm(1:(2*half.width+middle.bit),
                          half.width+0.5+0.5*middle.bit,
                          2*taper.width.factor*half.width)
        kernel <- sweep(kernel,2,gaussian,'*')
        kernel <- sweep(kernel,1,gaussian,'*')
      }
      return(kernel)
    }
    
    #so this makes the kernal, which then gets put into the calculate.foote.novelty function, below, along with dm
    
# 2. calculate FN
    
    calculate.foote.novelty <- function(dm, kernel) {
      # Calculate the Foote novelty given a distance matrix dm and the Foote kernel
      n.date <- nrow(dm)
      kernel.width <- ncol(kernel)
      novelty <- mat.or.vec(n.date,1) * NA
      n.step <- n.date - kernel.width
      for (i in 1:n.step) {
        ind <- i-1+(1:kernel.width)
        novelty[i+ceiling(kernel.width/2)] <- sum(dm[ind,ind] * kernel)
      }
      return(novelty)
    }
    
     
# 3.  bootstrap
    
    diag.mm <- function(mat, offset=0, in.diag=c()) {
      n <- dim(mat)[1]
      m <- n-abs(offset)
      if (length(in.diag) == 0) {
        out.diag <- mat.or.vec(m,1)
        for (i in 1:m) {
          out.diag[i] <- mat[i, i+offset]
        }
        return(out.diag)
      }
      else {
        for (i in 1:m) {
          mat[i, i+offset] <- in.diag[i]
        }
        return(mat)
      }
    }
    
    shuffle.diagonals <- function(mat, symm=TRUE) {
      n <- dim(mat)[1]
      for (i in 0:(n-1)) {
        the.diag <- diag.mm(mat, offset=i)
        shuffled.diag <- sample(the.diag)
        mat <- diag.mm(mat, offset=i, in.diag=shuffled.diag)
      }
      mat[lower.tri(mat)] <- 0
      mat <- mat + t(mat) - diag(diag(mat))
      return(mat)
    }
    
    shuffled.bootstrap <- function(dm, kernel, n.boot) {
      # scrambled bootstrap
      n.boot <- 100
      foote.novelty <- calculate.foote.novelty(dm, kernel)
      n.nov <- length(foote.novelty)
      foote.novelty.scrambled <- mat.or.vec(n.boot, n.nov)
      for (i.boot in 1:n.boot) {
        shuffled.dm <- shuffle.diagonals(dm)
        foote.novelty.scrambled[i.boot,] <- calculate.foote.novelty(shuffled.dm, kernel)
      }
      thresh <- quantile(foote.novelty.scrambled, c(0.025,0.975), na.rm = T)
      return(thresh)
    }
    
# 4.  bind previous together, run, and return results in list
    run.foot.novelty <- function(distance.matrix, half.width,  n.boot = 1000){
      
      # results list to return:
      return.list <- list()
      
      # basic novelty
      kernel <- make.foote.kernel(half.width = half.width) # choose your half width; smaller half widths give higher resolution, but less power to detect discontinuities; larger half widths give less resolution, but more power. 
      
      foote.novelty <- calculate.foote.novelty(distance.matrix, kernel)
      
      # bootstrap
      thresh <- shuffled.bootstrap(distance.matrix, kernel, n.boot = n.boot ) # choose your number of bootstrap iterations
      
      #return thresholds
      return.list$Thresh <-thresh
      
      #=================
      # a simple plot of novelty including very simple 95% confidence thresholds
      
      print(plot(foote.novelty,type='b', main = paste('Novelty with half.width', half.width)))
      print(abline(h=thresh))
      
      # sort data for writing
      foote.res<-as.data.frame(foote.novelty)
      foote.res$year <- rownames(distance.matrix)
      
      # add results to return list
      return.list$Foote.res <- foote.res
      
      return(return.list)
    }

#RUNNING FOOTE NOVELTY FOR DIFFERENT WIDTHS     
    # run through width vector

    c <- 1
    y <- 1
    
    for (i in width.vector){
      foote.results[y:(y+years-1),3] <- i
      
      new.nov <- run.foot.novelty(dm, half.width = i , n.boot = n.boot)
      thresholds[c,] <- c(i, new.nov$Thresh)
      
      #foote.header<-c(foote.header, as.character(i))
      foote.results[y:(y+years-1),2] <- new.nov$Foote.res[,1]  
      foote.results[y:(y+years-1),1] <- yearnames
      
      c <- c+1
      y <- y + years
    }
    
    list.to.return <- list()
    list.to.return$Foote.res <- foote.results
    list.to.return$Thresh <- thresholds
    
    return(list.to.return)
    
    
  }

#START EXCLUDING VARIABLES LOOP

  res_full <- data.frame() # the big results dataframe
  pdf(save.directory) # open pdf to save plots
  
  for (i in c(0,levels(as.factor(data$haldtopic)))) {
    
    cat('\n**************************************\n')
    print(paste('Excluding topic ',i))
    
    d1<-subset(data, !haldtopic==i)
  
#get the data in the right shape for a distance matrix
d2 <- ddply(d1, .(haldtopic, year), summarise, mean=mean(prob))

d3<-dcast(d2,year~haldtopic, value.var="mean")
#b<-dcast(minus.var, year~haldtopic)
#b$year<-NULL
#b[order(b$year)]

#difference if needed

#b<-as.matrix(b)
#b<-scale(b)
#b<-diff(b,differences=1) 
d4<-data.frame(diff(as.matrix(d3), differences=1)) #NOTE:difference twice here

#use euclidean distance and scale
#transpose
d4$year<-NULL
rwsums<-rowSums(d4)
d4<-d4/rwsums
d5<-d4
d5$year<-NULL
d5<-as.matrix(d5)
d3.1<-d3[-c(1),] #If rho<0.25 then skip this step
year<-unique(d3.1$year) 
rownames(d5)<-year
d7<-t(d5)
d8<-KLdiv(as.matrix(d7))
d9<- d8
d9[lower.tri(d9)] <- 0
dm.ut<- d9
d9<- d8
d9[upper.tri(d9)] <- 0
dm.lt<- d9
dm.ut.s<- dm.ut + t(dm.ut)
dm.lt.s<- dm.lt + t(dm.lt)
dm.s<- dm.ut.s + dm.lt.s
dm.s<-sqrt(dm.s)
dm<-dm.s
dmh<-melt(dm)
#dmh<-as.matrix(dm)
names(dmh)<-c("year1", "year2", "distance")
    
    #name years in matrix, removing the first element to account for the differencing
   # yearmod<-tail(unique(data$year),-1) #removed -1
   # rownames(dm)<-yearmod
    #colnames(dm)<-yearmod
    #if not differencing use this:
    #year<-unique(data$year)
    #rownames(dm)<-year
    #colnames(dm)<-year
   
#heatmap
    par(mfrow= c(1,1))
 
    if (i == 0){
      #heatmap(dmh ,Rowv= NA, Colv = NA, main = 'Heatmap with all variables')
    hplot<-ggplot()+
geom_tile(data=dmh, aes(x=year1,y=year2,fill=distance))+
scale_fill_continuous(low="lightgoldenrod1", high="coral3")+
ylab("year")+
xlab("year")+
  ggtitle("Heatmap with all variables")+
guides(colour=FALSE, fill=FALSE)+
scale_x_continuous(breaks=pretty_breaks(n=5), limits=c(min(dmh$year1), max(dmh$year1)))+#
scale_y_continuous(breaks=pretty_breaks(n=5), limits=c(min(dmh$year2), max(dmh$year2)))+
theme_classic(base_size = 12, base_family = "sans")+
theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), legend.position="bottom", text=element_text(size=10,  family="sans", colour = 'black'))
    print(hplot)
    }
    else{
      title<-(paste("Heatmap without topic", i ))
      #heatmap(dmh ,Rowv= NA, Colv = NA, main = paste('Heatmap without variable', i))
      ggplot()+
geom_tile(data=dmh, aes(x=year1,y=year2,fill=distance))+
scale_fill_continuous(low="lightgoldenrod1", high="coral3")+
ylab("year")+
xlab("year")+
  ggtitle(title)+
guides(colour=FALSE, fill=FALSE)+
scale_x_continuous(breaks=pretty_breaks(n=5), limits=c(min(dmh$year1), max(dmh$year1)))+#
scale_y_continuous(breaks=pretty_breaks(n=5), limits=c(min(dmh$year2), max(dmh$year2)))+
theme_classic(base_size = 12, base_family = "sans")+
theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), legend.position="bottom", text=element_text(size=10,  family="sans", colour = 'black'))
      print(hplot)
      }

#Running foote novelty
    #calculate max_k, and use as upperlimit on k

    max_k<-floor((length(unique(rownames(dm)))-2)/2)
    
    #pdf(paste('novelty_excl_',i, '.pdf', sep = ''))
    par(mfrow = c(3,2))
    foote.results<-novelty.analysis(dm, c(1:max_k)) #here set the range of kernal half-widths you want to use. 

    #dev.off()

    #put foote.results into a nice data frame.  This is the data frame which has to be extended so that it has an extra column telling us what variable is excluded (say "1" or "0" for "no variables excluded; so that if there are n variables, the final data frame will be these results x n variables long)
#plot nicely

    t<-foote.results$Thresh
    td<-as.data.frame(t)
    f<-foote.results$Foote.res
    fd<-as.data.frame(f)
    res<-merge(fd, t, by.x="hw", by.y="hw")
    res$year<-as.numeric(as.character(res$year))
    res$foote.novelty<-as.numeric(as.character(res$foote.novelty))
    res$upper<-ifelse(res$foote.novelty>=res$upper_97.5, 1, 0)
    res$lower<-ifelse(res$foote.novelty<=res$lower_2.5, 1, 0)
    res$excl_var <- c(rep(i,length(res[,1])))
    res<-as.data.table(res)
res<-res %>% group_by(hw) %>% mutate(bin = cut(foote.novelty, breaks = 30,labels=1:30, include.lowest = TRUE))
res<-as.data.frame(res)
res$bin<-as.factor(res$bin)
    res$revcons<-as.character(ifelse(res$foote.novelty>=res$upper_97.5, "rev", ifelse(res$foote.novelty<=res$lower_2.5, "cons", "neither")))
    res$revcons[is.na(res$revcons)] <- "NA"
res$revcons<- factor(res$revcons, levels = c("rev", "cons", "NA"))
res<-as.data.frame(res)
    # add newest results to big dataframe
    res_full <- rbind(res_full,res) 
    
    #Plot FNplot
  if(i ==0){
    par(mfrow= c(1,1))
    title<-(paste("FNplot of all ecology papers"))
    fnplot2<-ggplot()+
    geom_tile(data=res_full, aes(x=year,y=hw,fill=as.factor(bin)))+
    scale_fill_manual(values=c(pal1), na.value=NA)+
    geom_point(data=res_full, aes(x=year,y=hw, colour=as.factor(revcons)), size=2, alpha=1)+
    scale_colour_manual(values=c(pal2))+
    ylab("k")+
    xlab("year")+
    ggtitle(title)+
    guides(colour=FALSE, fill=FALSE)+
    #geom_rect(aes(xmin=1895, xmax=1905, ymin=0, ymax=20), fill="red", alpha=0.2)+ #revolution 1
    #geom_rect(aes(xmin=1950, xmax=1994, ymin=0, ymax=59), fill="red", alpha=0.2)+ #revolution 1
    scale_x_continuous(breaks=pretty_breaks(n=5), limits=c(min(res_full$year), max(res_full$year)))+#
    scale_y_continuous(breaks=pretty_breaks(n=10), limits=c(0, max_k))+
    theme_classic(base_size = 12, base_family = "sans")+
    theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), legend.position="bottom", text=element_text(size=10,  family="sans", colour = 'black'))
    print(fnplot2)
  }
  else{
    par(mfrow= c(1,1))
    title<-(paste("FNplot of ecology papers excl. topic", i ))
  
    fnplot2<-ggplot()+
    geom_tile(data=res_full, aes(x=year,y=hw,fill=as.factor(bin)))+
    scale_fill_manual(values=c(pal1), na.value=NA)+
    geom_point(data=res_full, aes(x=year,y=hw, colour=as.factor(revcons)), size=2, alpha=1)+
    scale_colour_manual(values=c(pal2))+
    ylab("k")+
    xlab("year")+
    ggtitle(title)+
    guides(colour=FALSE, fill=FALSE)+
    #geom_rect(aes(xmin=1895, xmax=1905, ymin=0, ymax=20), fill="red", alpha=0.2)+ #revolution 1
    #geom_rect(aes(xmin=1950, xmax=1994, ymin=0, ymax=59), fill="red", alpha=0.2)+ #revolution 1
    scale_x_continuous(breaks=pretty_breaks(n=5), limits=c(min(res_full$year), max(res_full$year)))+#
    scale_y_continuous(breaks=pretty_breaks(n=10), limits=c(0, max_k))+
    theme_classic(base_size = 12, base_family = "sans")+
    theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), legend.position="bottom", text=element_text(size=10,  family="sans", colour = 'black'))
    print(fnplot2)
      }
  }
#Given these data, I will then figure out how to identify which variables are most important to a revolution.  Not exactly sure how --- there are various metrics I can use. 

  dev.off() #close pdf where we were saving everything
  write.csv(res_full, "ecology_topics_all.csv", row.names=FALSE)
  write.csv(dm, "data_matrix.csv", row.names=FALSE)
  return(res_full)
}
```

```{r}
res.full <- variables_effect(data)
res.full<-res.full%>%
  arrange(excl_var,year,hw)
res.full$revcons[is.na(res.full$revcons)] <- "NA"
res.full<-res.full[complete.cases(res.full), ]
res.full$revcons<- factor(res.full$revcons, levels = c("rev", "cons", "NA"))
write.csv(res.full, "ecology_revolution_dropout.csv", row.names=FALSE)
res.rev<-subset(res.full, revcons=="rev")
```

```{r}

```

